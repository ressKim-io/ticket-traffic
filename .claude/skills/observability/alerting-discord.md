# Alerting & Discord ê°€ì´ë“œ

Prometheus AlertManager ì„¤ì • ë° Discord ì›¹í›… ì—°ë™

## Quick Reference (ê²°ì • íŠ¸ë¦¬)

```
ì•Œë¦¼ ì±„ë„ ì„ íƒ?
    â”‚
    â”œâ”€ ê¸´ê¸‰ (Critical) â”€â”€â”€â”€> PagerDuty / Opsgenie + Discord
    â”œâ”€ ê²½ê³  (Warning) â”€â”€â”€â”€â”€> Discord / Slack
    â””â”€ ì •ë³´ (Info) â”€â”€â”€â”€â”€â”€â”€â”€> Discord (ë³„ë„ ì±„ë„)

ì•Œë¦¼ ì„¤ì • ë°©ì‹?
    â”‚
    â”œâ”€ Prometheus Stack â”€â”€> AlertManager (ê¸°ë³¸)
    â”œâ”€ Grafana â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> Grafana Alerting
    â””â”€ í´ë¼ìš°ë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> CloudWatch / Azure Monitor
```

---

## CRITICAL: AlertManager ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AlertManager Flow                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Prometheus â”€â”€(alert rules)â”€â”€> AlertManager                  â”‚
â”‚                                      â”‚                       â”‚
â”‚                               â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                               â”‚             â”‚                â”‚
â”‚                          Grouping      Routing               â”‚
â”‚                               â”‚             â”‚                â”‚
â”‚                          Inhibition    Silencing             â”‚
â”‚                               â”‚             â”‚                â”‚
â”‚                               â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                      â”‚                       â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                              â”‚       â”‚       â”‚               â”‚
â”‚                          Discord  Slack  PagerDuty           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### í•µì‹¬ ê°œë…

| ê°œë… | ì„¤ëª… |
|------|------|
| **Grouping** | ìœ ì‚¬ ì•Œë¦¼ ê·¸ë£¹í™” (ë…¸ì´ì¦ˆ ê°ì†Œ) |
| **Routing** | ì¡°ê±´ì— ë”°ë¥¸ ì•Œë¦¼ ì „ì†¡ ê²½ë¡œ |
| **Inhibition** | íŠ¹ì • ì•Œë¦¼ì´ ë‹¤ë¥¸ ì•Œë¦¼ ì–µì œ |
| **Silencing** | ì¼ì‹œì  ì•Œë¦¼ ìŒì†Œê±° |

---

## AlertManager ì„¤ì •

### ê¸°ë³¸ ì„¤ì • (alertmanager.yaml)

```yaml
global:
  resolve_timeout: 5m
  # SMTP ì„¤ì • (ì´ë©”ì¼)
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alertmanager@example.com'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: 'password'

# ë¼ìš°íŒ… ê·œì¹™
route:
  # ê¸°ë³¸ ìˆ˜ì‹ ì
  receiver: 'discord-warning'
  # ê·¸ë£¹í™” ê¸°ì¤€
  group_by: ['alertname', 'namespace', 'severity']
  # ê·¸ë£¹ ëŒ€ê¸° ì‹œê°„
  group_wait: 30s
  # ê·¸ë£¹ ì¬ì „ì†¡ ê°„ê²©
  group_interval: 5m
  # ë°˜ë³µ ì „ì†¡ ê°„ê²©
  repeat_interval: 4h

  # í•˜ìœ„ ë¼ìš°íŠ¸
  routes:
    # Critical ì•Œë¦¼ â†’ PagerDuty + Discord
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      continue: true  # ë‹¤ìŒ ë¼ìš°íŠ¸ë„ ì ìš©

    - match:
        severity: critical
      receiver: 'discord-critical'

    # Warning ì•Œë¦¼ â†’ Discord
    - match:
        severity: warning
      receiver: 'discord-warning'

    # íŠ¹ì • íŒ€ ì•Œë¦¼
    - match:
        team: backend
      receiver: 'discord-backend'

    - match:
        team: infra
      receiver: 'discord-infra'

# ì•Œë¦¼ ì–µì œ ê·œì¹™
inhibit_rules:
  # Criticalì´ ìˆìœ¼ë©´ ê°™ì€ alertnameì˜ Warning ì–µì œ
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'namespace']

# ìˆ˜ì‹ ì ì •ì˜
receivers:
  - name: 'discord-critical'
    discord_configs:
      - webhook_url: 'https://discord.com/api/webhooks/xxx/yyy'
        title: 'ğŸ”´ CRITICAL Alert'
        message: |
          **{{ .Status | toUpper }}**: {{ .CommonAnnotations.summary }}
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Namespace:* {{ .Labels.namespace }}
          *Description:* {{ .Annotations.description }}
          {{ end }}

  - name: 'discord-warning'
    discord_configs:
      - webhook_url: 'https://discord.com/api/webhooks/xxx/zzz'
        title: 'ğŸŸ¡ Warning Alert'
        message: |
          **{{ .Status | toUpper }}**: {{ .CommonAnnotations.summary }}
          {{ range .Alerts }}
          *Alert:* {{ .Labels.alertname }}
          *Description:* {{ .Annotations.description }}
          {{ end }}

  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: 'your-pagerduty-service-key'
        severity: critical

  - name: 'discord-backend'
    discord_configs:
      - webhook_url: 'https://discord.com/api/webhooks/backend/xxx'

  - name: 'discord-infra'
    discord_configs:
      - webhook_url: 'https://discord.com/api/webhooks/infra/xxx'
```

---

## Discord ì›¹í›… ì„¤ì •

### ì›¹í›… ìƒì„±

```
1. Discord ì„œë²„ ì„¤ì • â†’ ì—°ë™ â†’ ì›¹í›„í¬
2. ìƒˆ ì›¹í›„í¬ ë§Œë“¤ê¸°
3. ì±„ë„ ì„ íƒ (alerts-critical, alerts-warning ë“±)
4. ì›¹í›„í¬ URL ë³µì‚¬
```

### AlertManager 0.25+ ë„¤ì´í‹°ë¸Œ Discord

```yaml
# alertmanager.yaml (v0.25+)
receivers:
  - name: 'discord'
    discord_configs:
      - webhook_url: 'https://discord.com/api/webhooks/xxx/yyy'
        title: '{{ template "discord.title" . }}'
        message: '{{ template "discord.message" . }}'
```

### ì»¤ìŠ¤í…€ í…œí”Œë¦¿

```yaml
# alertmanager-templates.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-templates
  namespace: monitoring
data:
  discord.tmpl: |
    {{ define "discord.title" }}
    {{ if eq .Status "firing" }}ğŸ”¥{{ else }}âœ…{{ end }} {{ .CommonLabels.alertname }}
    {{ end }}

    {{ define "discord.message" }}
    **Status**: {{ .Status | toUpper }}
    **Severity**: {{ .CommonLabels.severity }}
    {{ if .CommonAnnotations.summary }}
    **Summary**: {{ .CommonAnnotations.summary }}
    {{ end }}

    {{ range .Alerts }}
    ---
    **Alert**: {{ .Labels.alertname }}
    **Namespace**: {{ .Labels.namespace | default "N/A" }}
    **Pod**: {{ .Labels.pod | default "N/A" }}
    {{ if .Annotations.description }}
    **Description**: {{ .Annotations.description }}
    {{ end }}
    {{ if .Annotations.runbook_url }}
    **Runbook**: {{ .Annotations.runbook_url }}
    {{ end }}
    {{ end }}
    {{ end }}
```

---

## Prometheus Alert Rules

### í•µì‹¬ ì•Œë¦¼ ê·œì¹™

```yaml
# prometheus-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kubernetes-alerts
  namespace: monitoring
spec:
  groups:
    - name: kubernetes-pods
      rules:
        # Pod CrashLoopBackOff
        - alert: PodCrashLooping
          expr: |
            sum(rate(kube_pod_container_status_restarts_total[15m])) by (namespace, pod) > 0
          for: 5m
          labels:
            severity: warning
            team: infra
          annotations:
            summary: "Pod {{ $labels.pod }} is crash looping"
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has restarted more than 0 times in 15 minutes"
            runbook_url: "https://wiki.example.com/runbooks/pod-crashloop"

        # Pod Not Ready
        - alert: PodNotReady
          expr: |
            sum by (namespace, pod) (kube_pod_status_phase{phase!="Running",phase!="Succeeded"}) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.pod }} is not ready"
            description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been not ready for 15 minutes"

        # High Memory Usage
        - alert: ContainerHighMemory
          expr: |
            (container_memory_working_set_bytes / container_spec_memory_limit_bytes) > 0.9
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Container memory usage > 90%"
            description: "Container {{ $labels.container }} in {{ $labels.namespace }}/{{ $labels.pod }} is using > 90% memory"

    - name: kubernetes-nodes
      rules:
        # Node Not Ready
        - alert: NodeNotReady
          expr: |
            kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 5m
          labels:
            severity: critical
            team: infra
          annotations:
            summary: "Node {{ $labels.node }} is not ready"
            description: "Node {{ $labels.node }} has been not ready for 5 minutes"

        # Node High CPU
        - alert: NodeHighCPU
          expr: |
            (1 - avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) > 0.9
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Node CPU usage > 90%"
            description: "Node {{ $labels.instance }} CPU usage is above 90% for 10 minutes"

        # Node Disk Space Low
        - alert: NodeDiskSpaceLow
          expr: |
            (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes) < 0.1
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Node disk space < 10%"
            description: "Node {{ $labels.instance }} has less than 10% disk space available"

    - name: application-slo
      rules:
        # High Error Rate
        - alert: HighErrorRate
          expr: |
            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
            /
            sum(rate(http_requests_total[5m])) by (service)
            > 0.05
          for: 5m
          labels:
            severity: critical
            team: backend
          annotations:
            summary: "Service {{ $labels.service }} error rate > 5%"
            description: "Service {{ $labels.service }} has error rate above 5% for 5 minutes"
            runbook_url: "https://wiki.example.com/runbooks/high-error-rate"

        # High Latency (p99)
        - alert: HighLatencyP99
          expr: |
            histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service))
            > 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Service {{ $labels.service }} p99 latency > 1s"
            description: "Service {{ $labels.service }} p99 latency is above 1 second"
```

---

## ì•Œë¦¼ ë¼ìš°íŒ… ì˜ˆì‹œ

### íŒ€ë³„ ë¼ìš°íŒ…

```yaml
route:
  receiver: 'default-discord'
  routes:
    # Backend íŒ€
    - match:
        team: backend
      receiver: 'discord-backend'
      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-backend'
          continue: true

    # Infra íŒ€
    - match:
        team: infra
      receiver: 'discord-infra'
      routes:
        - match:
            severity: critical
          receiver: 'pagerduty-infra'

    # íŠ¹ì • ì„œë¹„ìŠ¤
    - match:
        service: payment
      receiver: 'discord-payment-critical'
```

### ì‹œê°„ëŒ€ë³„ ë¼ìš°íŒ…

```yaml
route:
  receiver: 'discord-default'
  routes:
    # ì—…ë¬´ ì‹œê°„ (09-18ì‹œ)
    - match:
        severity: critical
      active_time_intervals:
        - business-hours
      receiver: 'slack-critical'

    # ì—…ë¬´ ì™¸ ì‹œê°„
    - match:
        severity: critical
      active_time_intervals:
        - off-hours
      receiver: 'pagerduty-critical'

time_intervals:
  - name: business-hours
    time_intervals:
      - weekdays: ['monday:friday']
        times:
          - start_time: '09:00'
            end_time: '18:00'
  - name: off-hours
    time_intervals:
      - weekdays: ['monday:friday']
        times:
          - start_time: '00:00'
            end_time: '09:00'
          - start_time: '18:00'
            end_time: '24:00'
      - weekdays: ['saturday', 'sunday']
```

---

## Silencing (ì•Œë¦¼ ìŒì†Œê±°)

### CLIë¡œ Silence ìƒì„±

```bash
# amtoolë¡œ silence ìƒì„±
amtool silence add alertname=PodCrashLooping namespace=staging \
  --comment="Staging maintenance" \
  --author="admin" \
  --duration=2h

# Silence ëª©ë¡
amtool silence query

# Silence í•´ì œ
amtool silence expire <silence-id>
```

### APIë¡œ Silence ìƒì„±

```bash
curl -X POST http://alertmanager:9093/api/v2/silences \
  -H "Content-Type: application/json" \
  -d '{
    "matchers": [
      {"name": "alertname", "value": "PodCrashLooping", "isRegex": false},
      {"name": "namespace", "value": "staging", "isRegex": false}
    ],
    "startsAt": "2024-01-15T10:00:00Z",
    "endsAt": "2024-01-15T12:00:00Z",
    "createdBy": "admin",
    "comment": "Staging maintenance"
  }'
```

---

## ëª¨ë‹ˆí„°ë§

### AlertManager ë©”íŠ¸ë¦­

```promql
# ë°œì†¡ëœ ì•Œë¦¼ ìˆ˜
sum(alertmanager_notifications_total) by (integration)

# ì•Œë¦¼ ë°œì†¡ ì‹¤íŒ¨
sum(alertmanager_notifications_failed_total) by (integration)

# í™œì„± ì•Œë¦¼ ìˆ˜
alertmanager_alerts{state="active"}

# Silenced ì•Œë¦¼ ìˆ˜
alertmanager_silences{state="active"}
```

### Grafana ëŒ€ì‹œë³´ë“œ

```json
{
  "panels": [
    {
      "title": "Active Alerts by Severity",
      "targets": [{
        "expr": "sum(ALERTS{alertstate=\"firing\"}) by (severity)",
        "legendFormat": "{{severity}}"
      }]
    },
    {
      "title": "Notifications Sent",
      "targets": [{
        "expr": "rate(alertmanager_notifications_total[1h])",
        "legendFormat": "{{integration}}"
      }]
    }
  ]
}
```

---

## Anti-Patterns

| ì‹¤ìˆ˜ | ë¬¸ì œ | í•´ê²° |
|------|------|------|
| ëª¨ë“  ì•Œë¦¼ Critical | ì•Œë¦¼ í”¼ë¡œ | severity ì ì ˆíˆ êµ¬ë¶„ |
| group_wait ë„ˆë¬´ ì§§ìŒ | ì•Œë¦¼ í­íƒ„ | 30ì´ˆ ì´ìƒ ê¶Œì¥ |
| runbook ì—†ìŒ | ëŒ€ì‘ ì§€ì—° | ì•Œë¦¼ë§ˆë‹¤ runbook ë§í¬ |
| í…ŒìŠ¤íŠ¸ ì—†ì´ ì ìš© | ì•Œë¦¼ ëˆ„ë½ | ìŠ¤í…Œì´ì§• í…ŒìŠ¤íŠ¸ |
| ë‹¨ì¼ ì±„ë„ë§Œ ì‚¬ìš© | ë…¸ì´ì¦ˆ | ì‹¬ê°ë„ë³„ ì±„ë„ ë¶„ë¦¬ |

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### AlertManager
- [ ] ê¸°ë³¸ ì„¤ì • (group_wait, group_interval)
- [ ] ë¼ìš°íŒ… ê·œì¹™ (severity, team)
- [ ] ìˆ˜ì‹ ì ì„¤ì • (Discord, Slack, PagerDuty)
- [ ] ì–µì œ ê·œì¹™ (inhibit_rules)

### Alert Rules
- [ ] í•µì‹¬ ë©”íŠ¸ë¦­ ì•Œë¦¼ (Pod, Node, SLO)
- [ ] ì ì ˆí•œ severity ì§€ì •
- [ ] runbook_url í¬í•¨
- [ ] for ì ˆë¡œ í”Œë˜í•‘ ë°©ì§€

### Discord
- [ ] ì±„ë„ ë¶„ë¦¬ (critical, warning, info)
- [ ] ì›¹í›… ì„¤ì •
- [ ] ì»¤ìŠ¤í…€ í…œí”Œë¦¿ ì ìš©

### ìš´ì˜
- [ ] Silence ì ˆì°¨ ë¬¸ì„œí™”
- [ ] ì•Œë¦¼ ëŒ€ì‹œë³´ë“œ êµ¬ì„±
- [ ] ì •ê¸° ì•Œë¦¼ ë¦¬ë·°

**ê´€ë ¨ skill**: `/sre-sli-slo`, `/monitoring-metrics`, `/monitoring-troubleshoot`
